# 資料清理過程記錄

**原始檔案**: `cofacts_integrated_20251103_225657.xlsx`
**檔案位置**: `C:\Users\USER\Desktop\資料集清洗\cofacts\1_清洗(針對 replies_text 刪除 49,163 筆重複資料)`
**開始時間**: 2025-11-07 20:41:49
**原始資料筆數**: 109,174
**原始特徵數量**: 21

---

## 📄 論文用說明（可直接複製）

### 資料預處理方法

本研究採用系統化的資料清理流程，以確保資料品質並提升模型效能。資料清理過程包含三個主要階段：缺失值處理、重複值移除與異常值偵測。所有清理步驟均記錄於日誌檔案中，以確保研究的可重現性 (reproducibility)。

#### 3.1 缺失值處理

缺失值處理採用分層策略 (hierarchical strategy)：

1. **特徵層級處理**：當特徵的缺失率超過預設閾值時，該特徵將被移除。此策略基於資訊理論，認為缺失率過高的特徵對模型貢獻有限 (Little & Rubin, 2019)。

2. **資料列層級處理**：當資料列的缺失率超過預設閾值時，該筆資料將被移除。此做法可避免保留品質不佳的樣本，影響模型訓練效果。

3. **數值型特徵處理**：對於選定的數值型特徵，若存在缺失值則刪除該筆資料。此方法可保持數值資料的完整性與準確性，避免填補方法引入的偏差 (bias)。

4. **類別型特徵處理**：對於類別型特徵，缺失值以 'UNKNOWN' 標記。此方法可保留資料筆數，同時明確標示缺失狀態。

#### 3.2 重複值處理

重複值處理採用完全比對法 (exact matching)，當資料列的所有特徵值完全相同時，保留第一筆資料，刪除後續重複項。此方法可避免資料重複導致的模型過擬合問題。

#### 3.3 異常值偵測與處理

異常值偵測採用四分位距法 (Interquartile Range, IQR)，此方法對資料分布的假設較少，適用於各種類型的數值資料 (Tukey, 1977)。異常值定義如下：

```
Q1 = 第一四分位數 (25th percentile)
Q3 = 第三四分位數 (75th percentile)
IQR = Q3 - Q1
下界 = Q1 - 1.5 × IQR
上界 = Q3 + 1.5 × IQR
```

超出上下界範圍的數值即被視為異常值。異常值處理方式可選擇：
(1) 邊界值替換法：將異常值替換為對應的邊界值，保留資料筆數；
(2) 直接刪除法：刪除包含異常值的資料列，確保資料品質；
(3) 保留原值：用於探索性分析階段。

#### 參考文獻

- Little, R. J., & Rubin, D. B. (2019). *Statistical analysis with missing data* (Vol. 793). John Wiley & Sons.
- Tukey, J. W. (1977). *Exploratory data analysis* (Vol. 2). Reading, MA: Addison-Wesley.

---

## 🔧 詳細執行記錄

## 操作 1：關鍵字過濾

**執行時間**: 2025-11-07 20:42:59

### 關鍵字過濾分析

**選擇欄位**: replies_text
**過濾關鍵字**: 外送茶, 叫小姐, 定點茶, 被騙如何自救賴
**將刪除數量**: 24,011 筆 (21.99%)

- `replies_text` 包含 `外送茶`: 21,231 筆
- `replies_text` 包含 `叫小姐`: 23,654 筆
- `replies_text` 包含 `定點茶`: 13,203 筆
- `replies_text` 包含 `被騙如何自救賴`: 218 筆

### 執行結果

**刪除數量**: 24,011 筆
**剩餘數量**: 85,163 筆

---

## 操作 2：處理重複值

**執行時間**: 2025-11-07 20:45:35

### 去重執行結果

**判斷欄位**: articles_id, replies_text
**刪除數量**: 2,047 筆 (2.40%)
**剩餘數量**: 83,116 筆

---

## 操作 3：處理缺失值

**執行時間**: 2025-11-07 20:46:37

**結果**: 用戶跳過缺失值處理

---

## 操作 3：處理異常值

**執行時間**: 2025-11-07 20:46:44

**結果**: 用戶跳過異常值處理

---

## 儲存結果

**儲存時間**: 2025-11-07 20:47:53

**輸出檔案**: `cofacts_integrated_20251103_22_cleaned_20251107_204717_關鍵字過濾_去重.xlsx`
**檔案位置**: `C:\Users\USER\Desktop\資料集清洗\cofacts\1_清洗(針對 replies_text 刪除 49,163 筆重複資料)`
**清理步驟**: keyword_filter, duplicates

### 最終統計

| 項目 | 清理前 | 清理後 | 變化 |
|------|--------|--------|------|
| 資料筆數 | 109,174 | 83,116 | +26,058 (+23.87%) |
| 特徵數量 | 21 | 21 | +0 (+0.00%) |
| 缺失值 | 274,436 | 165,678 | +108,758 |
| 重複值 | 0 | 0 | +0 |

### 清理參數設定

- 特徵缺失閾值: 80%
- 資料列缺失閾值: 50%
- 異常值處理方式: replace

### 執行的清理步驟

1. 關鍵字過濾刪除 24,011 筆資料
2. 針對 articles_id, replies_text 刪除 2,047 筆重複資料

---

## 📊 論文用結果說明（可直接複製）

### 資料清理結果

經過系統化的資料清理流程後，原始資料集從 109,174 筆資料減少至 83,116 筆（移除 26,058 筆，約 23.87%），保留所有 21 個特徵。清理後的資料集缺失值從 274,436 個減少至 165,678 個，重複值從 0 筆減少至 0 筆，顯著提升了資料品質。

### 清理參數設定

本研究採用以下參數進行資料清理：

- **特徵缺失閾值**：80%
- **資料列缺失閾值**：50%
- **異常值處理方式**：邊界值替換法 (Boundary Value Replacement)

### 清理前後對比

| 項目 | 清理前 | 清理後 | 變化量 | 變化率 |
|------|--------|--------|--------|--------|
| 資料筆數 | 109,174 | 83,116 | +26,058 | +23.87% |
| 特徵數量 | 21 | 21 | +0 | +0.00% |
| 缺失值總數 | 274,436 | 165,678 | +108,758 | +39.63% |
| 重複值數量 | 0 | 0 | +0 | +0.00% |

### 資料品質評估

清理後資料集的整體缺失率為 9.49%，仍存在部分缺失值，建議進一步評估是否需要額外處理。

---

**清理完成時間**: 2025-11-07 20:47:57
**總操作數**: 2
**處理時長**: 368.32 秒
